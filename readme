# 🎙️ Speech Recognition Overview  
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Made with](https://img.shields.io/badge/Made%20with-Python-orange.svg)](https://www.python.org/)
[![Paper](https://img.shields.io/badge/Survey-Paper-red)]

语音识别（Speech Recognition, ASR, Automatic Speech Recognition）是人工智能中最重要的分支之一，旨在**将人类语音信号转化为文本**。  
近年来，随着深度学习和大规模预训练模型的发展，语音识别的准确率和应用范围都得到了显著提升。

---

## 📌 目录
- [背景与发展](#背景与发展)
- [主流方法](#主流方法)
- [常用数据集](#常用数据集)
- [开源工具与框架](#开源工具与框架)
- [应用场景](#应用场景)
- [参考资料](#参考资料)

---

## 🚀 背景与发展
语音识别的发展历程大致可以分为以下阶段：

1. **基于模板匹配 (1950s-1970s)**  
   - 动态时间规整 (Dynamic Time Warping, DTW)  
   - 早期的小词汇识别系统  

2. **统计建模时代 (1980s-2000s)**  
   - 隐马尔可夫模型 (Hidden Markov Model, HMM)  
   - 高斯混合模型 (Gaussian Mixture Model, GMM)  
   - 代表系统：CMU Sphinx  

3. **深度学习时代 (2010s-)**  
   - 深度神经网络 (DNN) 替代 GMM  
   - 循环神经网络 (RNN, LSTM, GRU)  
   - CTC (Connectionist Temporal Classification) & Attention 机制  

4. **端到端与预训练大模型 (2020s-)**  
   - Transformer, Conformer 架构  
   - 自监督预训练模型（Wav2Vec2.0, HuBERT, Whisper）  
   - 跨模态大模型推动语音-文本-视觉的统一  

---

## 🧠 主流方法
| 方法类别 | 代表模型 | 特点 |
|----------|----------|------|
| HMM-GMM | CMU Sphinx | 经典方法，低资源场景仍可用 |
| DNN-HMM | Kaldi | 声学建模提升，工业界广泛应用 |
| CTC | DeepSpeech | 端到端，省去对齐步骤 |
| Attention | Listen, Attend and Spell (LAS) | 利用注意力捕捉长依赖 |
| Transformer/Conformer | ESPnet, SpeechBrain | 并行训练，高性能 |
| 自监督预训练 | Wav2Vec2.0, HuBERT, Whisper | 利用未标注数据，跨语言迁移 |

---

## 📊 常用数据集
| 数据集 | 语言 | 大小 | 链接 |
|--------|------|------|------|
| [LibriSpeech](https://www.openslr.org/12) | 英语 | 1000h | 标准基准 |
| [TED-LIUM](https://www.openslr.org/19) | 英语 | 452h | 演讲数据 |
| [AISHELL-1](https://www.openslr.org/33) | 中文 | 178h | 开源中文语音 |
| [Common Voice](https://commonvoice.mozilla.org/) | 多语言 | >7000h | 社区贡献 |
| [GigaSpeech](https://github.com/SpeechColab/GigaSpeech) | 英语 | 10000h | 大规模开源语音 |

---

## 🛠️ 开源工具与框架
- [Kaldi](https://kaldi-asr.org/) - 传统/混合方法的经典工具包  
- [ESPnet](https://github.com/espnet/espnet) - 端到端语音处理框架  
- [SpeechBrain](https://speechbrain.github.io/) - PyTorch 语音工具包  
- [OpenAI Whisper](https://github.com/openai/whisper) - 多语言通用语音识别模型  
- [NVIDIA NeMo](https://github.com/NVIDIA/NeMo) - 大规模语音模型训练  

---

## 📱 应用场景
- **语音助手**（Siri, Alexa, 小爱同学）  
- **实时字幕与翻译**（会议转写，跨语言交流）  
- **无障碍服务**（听障人士辅助工具）  
- **车载系统**（语音导航与控制）  
- **智能客服与质检**（语音工单、呼叫中心）  

---

## 📖 参考资料
- 📘 Jurafsky, D., & Martin, J. H. *Speech and Language Processing* (3rd Edition draft) [[link](https://web.stanford.edu/~jurafsky/slp3/)]  
- 📘 Li, Jinyu, et al. "A Survey on Recent Deep Learning for ASR." *IEEE Transactions on Audio, Speech, and Language Processing* (2021). [[arXiv](https://arxiv.org/abs/2007.09192)]  
- 📘 Baevski, Alexei, et al. "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations." *NeurIPS 2020*. [[paper](https://arxiv.org/abs/2006.11477)]  
- 📘 Radford, Alec, et al. "Robust Speech Recognition via Large-Scale Weak Supervision." *OpenAI Whisper* (2022). [[GitHub](https://github.com/openai/whisper)]  


💡 如果你对 **语音识别综述** 感兴趣，可以 Star ⭐ 本项目，或提交 PR 补充更多内容！
